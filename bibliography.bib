@Article{compare-text-clustering-sokolov,
  author   = {СОКОЛОВ, П.В. and КАРУНА, Е.Н.},
  journal  = { МЕЖДУНАРОДНАЯ КОНФЕРЕНЦИЯ ПО МЯГКИМ ВЫЧИСЛЕНИЯМ И ИЗМЕРЕНИЯМ},
  title    = {СРАВНИТЕЛЬНЫЙ АНАЛИЗ МЕТОДОВ КЛАСТЕРИЗАЦИИ ТЕКСТОВОЙ ИНФОРМАЦИИ},
  year     = {2021},
  pages    = {155-158},
  abstract = {Работа посвящена сравнительному анализу методов кластеризации текстовой информации с использованием набора H-метрик. Исследованы: самоорганизующаяся сеть Кохонена, методы К-средних, спектральной кластеризации и агломеративной кластеризации. Рассмотрены особенности реализации алгоритмов и вопросы их оптимизации. Для наглядной визуализации результатов, применен метод снижения размерности, позволяющий на двумерной плоскости отобразить многомерное пространство данных. Сделаны выводы об эффективности исследованных алгоритмов.},
  keywords = { КЛАСТЕРИЗАЦИЯ ТЕКСТОВ, МЕТОД K-СРЕДНИХ, АГЛОМЕРАТИВНАЯ КЛАСТЕРИЗАЦИЯ, ТОЧНОСТЬ, F-МЕРА},
  owner    = { Санкт-Петербургский государственный электротехнический университет «ЛЭТИ» им. В.И. Ульянова (Ленина)},
  url      = {https://scm.etu.ru/assets/files/2021/scm21/papers/155-158.pdf},
}

@Article{method-text-clustering-andreev,
  author = {Андреев, А.М. and Березкин, Д.В. and Морозов, В.В. and Симаков, К.В.},
  title  = {Метод кластеризации документов текстовых коллекцийи синтеза аннотаций кластеров},
  owner  = {МГТУ им. Н.Э. Баумана},
}

@Misc{no-patterns,
  author    = {Silva, Marília Costa Rosendo and Siqueira, Felipe Alves and Tarrega, João Pedro Mantovani and Beinotti, João Vitor Pataca and Nunes, Augusto Sousa and Gardini, Miguel de Mattos and da Silva, Vinícius Adolfo Pereira and da Silva, Nádia Félix Felipe and de Carvalho, André Carlos Ponce de Leon Ferreira},
  title     = {No Pattern, No Recognition: a Survey about Reproducibility and Distortion Issues of Text Clustering and Topic Modeling},
  year      = {2022},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  doi       = {10.48550/ARXIV.2208.01712},
  keywords  = {Machine Learning (cs.LG), Computation and Language (cs.CL), Information Retrieval (cs.IR), Machine Learning (stat.ML), FOS: Computer and information sciences, I.2; I.2.7; I.5.3},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2208.01712},
}

@ARTICLE{deep-clustering-survey,
  author={Min, Erxue and Guo, Xifeng and Liu, Qiang and Zhang, Gen and Cui, Jianjing and Long, Jun},
  journal={IEEE Access},
  title={A Survey of Clustering With Deep Learning: From the Perspective of Network Architecture},
  year={2018},
  volume={6},
  number={},
  pages={39501-39514},
  doi={10.1109/ACCESS.2018.2855437}
}

@Inbook{text-clustering-survey,
  author="Aggarwal, Charu C.
  and Zhai, ChengXiang",
  editor="Aggarwal, Charu C.
  and Zhai, ChengXiang",
  title="A Survey of Text Clustering Algorithms",
  bookTitle="Mining Text Data",
  year="2012",
  publisher="Springer US",
  address="Boston, MA",
  pages="77--128",
  abstract="Clustering is a widely studied data mining problem in the text domains. The problem finds numerous applications in customer segmentation, classification, collaborative filtering, visualization, document organization, and indexing. In this chapter, we will provide a detailed survey of the problem of text clustering. We will study the key challenges of the clustering problem, as it applies to the text domain. We will discuss the key methods used for text clustering, and their relative advantages. We will also discuss a number of recent advances in the area in the context of social network and linked data.",
  isbn="978-1-4614-3223-4",
  doi="10.1007/978-1-4614-3223-4_4",
  url="https://doi.org/10.1007/978-1-4614-3223-4_4"
}

@INPROCEEDINGS{text-clustering-with-bert,
  author={Li, Yutong and Cai, Juanjuan and Wang, Jingling},
  booktitle={2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)},
  title={A Text Document Clustering Method Based on Weighted BERT Model},
  year={2020},
  volume={1},
  number={},
  pages={1426-1430},
  doi={10.1109/ITNEC48623.2020.9085059}
}

@Misc{end-to-end-clustering,
  author    = {Zhou, Jie and Cheng, Xingyi and Zhang, Jinchao},
  title     = {An end-to-end Neural Network Framework for Text Clustering},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1903.09424},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1903.09424},
}

@Electronic{word2vec-habr,
  organization = {Хабр},
  title        = {Word2vec в картинках},
  url          = {https://habr.com/ru/post/446530/},
  year         = {2019},
}

@Misc{word2vec,
  author    = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  title     = {Efficient Estimation of Word Representations in Vector Space},
  year      = {2013},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1301.3781},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1301.3781},
}

@article{word2vec-demo,
  title={Interactive Visualizations of Word Embeddings for K-12 Students},
  volume={36},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/21548},
  DOI={10.1609/aaai.v36i11.21548},
  number={11},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  author={Bandyopadhyay, Saptarashmi and Xu, Jason and Pawar, Neel and Touretzky, David},
  year={2022},
  month={Jun.},
  pages={12713-12720}
}

@Electronic{embeddings-habr,
  organization = {Хабр},
  title        = {Чудесный мир Word Embeddings: какие они бывают и зачем нужны?},
  url          = {https://habr.com/ru/company/ods/blog/329410/},
  year         = {2017},
}

@inproceedings{glove,
  added-at = {2016-02-18T12:02:38.000+0100},
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  biburl = {https://www.bibsonomy.org/bibtex/2a6e77a38c13e374ab250e13ae22993ec/thoni},
  booktitle = {EMNLP},
  interhash = {29813227df1eea94efa14c7df2b5553a},
  intrahash = {a6e77a38c13e374ab250e13ae22993ec},
  keywords = {deeplearning deepwiki glove semantic},
  pages = {1532--1543},
  timestamp = {2016-09-06T08:23:07.000+0200},
  title = {Glove: Global Vectors for Word Representation.},
  volume = 14,
  year = 2014
}

@Misc{elmo,
  author    = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  title     = {Deep contextualized word representations},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1802.05365},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1802.05365},
}


@article{conv-networks-clustering,
  author    = {Jiaming Xu and
               Bo Xu and
               Peng Wang and
               Suncong Zheng and
               Guanhua Tian and
               Jun Zhao},
  title     = {Self-Taught Convolutional Neural Networks for Short Text Clustering},
  journal   = {CoRR},
  volume    = {abs/1701.00185},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.00185},
  eprinttype = {arXiv},
  eprint    = {1701.00185},
  timestamp = {Thu, 12 Nov 2020 13:40:45 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/XuXWZTZX17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{mteb,
  doi = {10.48550/ARXIV.2210.07316},
  url = {https://arxiv.org/abs/2210.07316},
  author = {Muennighoff, Niklas and Tazi, Nouamane and Magne, Lo{\"\i}c and Reimers, Nils},
  title = {MTEB: Massive Text Embedding Benchmark},
  publisher = {arXiv},
  journal={arXiv preprint arXiv:2210.07316},
  year = {2022}
}

@article{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bert-simcse,
  author    = {Tianyu Gao and
               Xingcheng Yao and
               Danqi Chen},
  title     = {SimCSE: Simple Contrastive Learning of Sentence Embeddings},
  journal   = {CoRR},
  volume    = {abs/2104.08821},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.08821},
  eprinttype = {arXiv},
  eprint    = {2104.08821},
  timestamp = {Mon, 26 Apr 2021 17:25:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-08821.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Misc{condenser,
  author    = {Gao, Luyu and Callan, Jamie},
  title     = {Condenser: a Pre-training Architecture for Dense Retrieval},
  year      = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2104.08253},
  keywords  = {Computation and Language (cs.CL), Information Retrieval (cs.IR), FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2104.08253},
}

@Misc{transformer,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  title     = {Attention Is All You Need},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1706.03762},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1706.03762},
}

@Electronic{vector-search,
  organization = {Algolia Blog},
  title        = {What is vector search? - Algolia Blog},
  url          = {https://www.algolia.com/blog/ai/what-is-vector-search/},
  urldate      = {2023-02-09},
}

@Electronic{weaviate,
  organization = {Weaviate, B.V},
  title        = {Weaviate - vector search engine},
  url          = {https://weaviate.io/},
  urldate      = {2023-02-09},
}

@Electronic{milvus,
  organization = {Milvus},
  title        = {Vector database - Milvus},
  url          = {https://milvus.io/},
  urldate      = {2023-05-26},
}

@Electronic{pinecone,
  organization = {Pinecone Systems, Inc.},
  title        = {Vector Database for Vector Search | Pinecone},
  url          = {https://www.pinecone.io/},
  urldate      = {2023-05-26},
}

@article{faiss,
  title={Billion-scale similarity search with {GPUs}},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  volume={7},
  number={3},
  pages={535--547},
  year={2019},
  publisher={IEEE}
}

@Comment{jabref-meta: databaseType:bibtex;}
